# Pesto Take Home Assessment: Data Engineering Case Study (AdvertiseX)

## Context:

Imagine you are a data engineer working for AdvertiseX, a digital advertising technology company. AdvertiseX specializes in programmatic advertising and manages multiple online advertising campaigns for its clients. The company handles vast amounts of data generated by ad impressions, clicks, conversions, and more. 

### Data Sources and Formats:

- **Ad Impressions:**

	- Data Source: AdvertiseX serves digital ads to various online platforms and websites.
	- Data Format: Ad impressions data is generated in JSON format, containing information such as ad creative ID, user ID, timestamp, and the website where the ad was displayed.

- **Clicks and Conversions:**

	- Data Source: AdvertiseX tracks user interactions with ads, including clicks and conversions (e.g., sign-ups, purchases).
	- Data Format: Click and conversion data is logged in CSV format and includes event timestamps, user IDs, ad campaign IDs, and conversion type.

- **Bid Requests:**

	- Data Source: AdvertiseX participates in real-time bidding (RTB) auctions to serve ads to users.
	- Data Format: Bid request data is received in a semi-structured format, mostly in Avro, and includes user information, auction details, and ad targeting criteria.

## Problem Statement: 

- **Data Ingestion:** Implement a scalable data ingestion system capable of collecting and processing ad impressions (JSON), clicks/conversions (CSV), and bid requests (Avro) data. Ensure that the ingestion system can handle high data volumes generated in real-time and batch modes.
- **Data Processing:** Develop data transformation processes to standardize and enrich the data. Handle data validation, filtering, and deduplication. Implement logic to correlate ad impressions with clicks and conversions to provide meaningful insights.
- **Data Storage and Query Performance:** Select an appropriate data storage solution for storing processed data efficiently, enabling fast querying for campaign performance analysis. Optimize the storage system for analytical queries and aggregations of ad campaign data.
- **Error Handling and Monitoring:** Create an error handling and monitoring system to detect data anomalies, discrepancies, or delays. Implement alerting mechanisms to address data quality issues in real-time, ensuring that discrepancies are resolved promptly to maintain ad campaign effectiveness.

## Solution:

To address the data engineering requirements for AdvertiseX, we can design a scalable and efficient data processing pipeline using Apache Spark, Apache Kafka, and Apache Hive. Here's a comprehensive approach to the solution:

### Data Ingestion:

1. **Apache Kafka:** We'll use Apache Kafka as a distributed streaming platform to ingest real-time data from various sources (ad impressions, clicks/conversions, and bid requests).
2. **Kafka Topics:** Create separate Kafka topics for each data source
   - ```ad-impressions``` (for JSON ad impression data)
   - ```clicks-conversions``` (for CSV click and conversion data)
   - ```bid-requests``` (for Avro bid request data)
3. **Kafka Producers:** Develop Kafka producers to publish data to the respective topics. These producers can be integrated with the AdvertiseX ad serving systems, user interaction tracking systems, and real-time bidding platforms.
4. **Batch Data Ingestion:** For batch data ingestion (e.g., historical data), we can use Apache Spark to read the data from the respective sources and write it directly to the corresponding Kafka topics.

### Data Processing:

1. **Apache Spark Structured Streaming:** Use Apache Spark Structured Streaming to consume data from Kafka topics and perform data transformations and enrichment.
2. **Data Parsing and Validation:** Parse the incoming data based on the format (JSON, CSV, Avro) and apply data validation rules to ensure data quality.
3. **Data Transformation and Enrichment:** Perform necessary data transformations and enrichment, such as:
   - Standardize data formats
   - Handle deduplication
   - Correlate ad impressions with clicks and conversions
   - Enrich data with additional metadata (e.g., campaign details, user information)
4. **Apache Hive:** Use Apache Hive as a data warehouse to store the processed and enriched data in an optimized columnar format (e.g., Apache Parquet or Apache ORC).
5. **Hive Partitioning:** Partition the Hive tables based on relevant columns (e.g., date, campaign ID) to improve query performance and optimize for common analytical queries.

### Data Storage and Query Performance:

1. **Apache Hive:** Leverage Apache Hive as the data warehouse solution for storing processed data in an optimized columnar format.
2. **Hive Partitioning and Bucketing:** Partition and bucket the Hive tables based on commonly used columns (e.g., date, campaign ID) to improve query performance and enable pruning of unnecessary data during queries.
3. **Hive Indexing:** Create Hive indexes on relevant columns to further enhance query performance for specific types of queries.
4. **Hive Views and Materialized Views:** Create Hive views and materialized views to simplify complex analytical queries and improve query response times.

